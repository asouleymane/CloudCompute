{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DynamoDB\n",
    "\n",
    "DynamoDB is one of the storage services offered inside AWS. It's fast and a flexible NoSQL database service for all kinds of applications. Amazon claims it is consistent and offers single-digit millisecond latency at any scale. The in-memory cache that can reduce Amazon DynamoDB response times from milliseconds to microseconds, even at millions of requests per second. It supports both document and key-value store models. Speaking of Document-oriented databases, they are one of the main categories of NoSQL databases.  They are designed for storing, retrieving and managing document-oriented information, also known as semi-structured data. \n",
    "\n",
    "Relational databases generally store data in separate tables that are defined by the programmer, and a single object may be spread across several tables. Document databases store all information for a given object in a single instance in the database, and every stored object can be different from every other. \n",
    "\n",
    "Its flexible data model, reliable performance, and automatic scaling of throughput capacity, makes it a great fit for mobile, web, gaming, ad tech, IoT, and many other applications.\n",
    "\n",
    "This notebook outlines some operations on DynamoDB databases using boto3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Table\n",
    "\n",
    "DynamoDB is schemaless (except the key schema). It means, you have to specify the key schema (attribute name and its type) when creating the table. There is no need to specify other non-key attributes. You can insert records into the table in nosql format with different schema for each record and make sure to include the keys while inserting.\n",
    "\n",
    "From the [documentation page](http://boto3.readthedocs.io/en/latest/reference/services/dynamodb.html#DynamoDB.Client.create_table), \n",
    "\n",
    "AttributeDefinitions is defined as - an array of attributes that describe the key schema for the table and indexes. It represents an attribute for describing the key schema for the table and indexes. \n",
    "\n",
    "KeySchema: Specifies the attributes that make up the primary key for a table or an index. The attributes in KeySchema must also be defined in the AttributeDefinitions array. \n",
    "\n",
    "Each KeySchemaElement in the array is composed of: \n",
    "- AttributeName - The name of this key attribute.\n",
    "- KeyType - The role that the key attribute will assume:\n",
    "    - HASH - partition key\n",
    "    - RANGE - sort key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create DynamoDB client and resource objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "\n",
    "# dynamodb = boto3.client('dynamodb')\n",
    "client = boto3.client('dynamodb')\n",
    "dynamodb = boto3.resource('dynamodb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In below function, we are checking in the Try block to see if a table already exists in the database with the name being passed to the function. If it does, then it will return nothing. But if the table doesn't exist then it will create one with name as in input parameter **table_name**, a primary key field with the value in input parameter **key_name** with its type as mentioned in the input parameter **KeyType**.\n",
    "\n",
    "It prints the message as either the table alreday exists or name of the newly created table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dynamodb_table(table_name, key_name,KeyType):\n",
    "    try:\n",
    "        response = client.describe_table(TableName=table_name)\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        print(\"DynamoDB table '\" + table_name + \"' does not appear to exist, creating...\")\n",
    "        table = dynamodb.create_table(\n",
    "                    TableName = table_name,\n",
    "                    KeySchema = [ { 'AttributeName': key_name,\n",
    "                                    'KeyType': 'HASH'  } ], # Partition key\n",
    "                    AttributeDefinitions = [ \n",
    "                                  { 'AttributeName': key_name,\n",
    "                                  'AttributeType': KeyType \n",
    "                                  } ],\n",
    "                    ProvisionedThroughput = { 'ReadCapacityUnits': 1,\n",
    "                                              'WriteCapacityUnits': 1 }\n",
    "                )\n",
    "        # Wait until the table exists.\n",
    "        table.meta.client.get_waiter('table_exists').wait(TableName=table_name) \n",
    "        print(\"DynamoDB table '\" + table_name + \"' created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the create_dynamodb_table() method to create \"dsa_courses\" table with \"courseid\" as the primary key field that is of type number. The value \"N\" in below call to create_dynamodb_table() function tells the data type of primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_dynamodb_table(\"dsa_courses\",\"courseid\",\"N\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to DynamoDB\n",
    "\n",
    "A table object lets you write records to the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = dynamodb.Table('dsa_courses')\n",
    "\n",
    "table.put_item(\n",
    "   Item={\n",
    "        'coursename': 'Intro to data science',\n",
    "        'courseid': 7600,\n",
    "        'credits': 3\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read from DynamoDB\n",
    "\n",
    "Retreive records from the table. Use the get_item() method to read the item from a table. You must specify the primary key value to read any item from the table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "response = table.get_item(\n",
    "   Key={\n",
    "        'courseid': 7600\n",
    "    }\n",
    ")\n",
    "\n",
    "item = response['Item']\n",
    "name = item['coursename']\n",
    "\n",
    "print(item)\n",
    "print(\"Welcome to, {}\" .format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Items\n",
    "\n",
    "Update a record in the table. Use the update_item() method to modify an existing item. You can update values of existing attributes, add new attributes, or remove attributes.\n",
    "\n",
    "In below example, we are updating the course name from 'Intro to data science' to 'Introduction to data science'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table.update_item(\n",
    "    Key={\n",
    "        'courseid':7600\n",
    "    },\n",
    "    UpdateExpression='SET coursename= :val1',\n",
    "    ExpressionAttributeValues={\n",
    "        ':val1': 'Introduction to data science'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = client.delete_table(\n",
    "    TableName='dsa_courses'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets insert records into a DynamoDB table for the courses offered in DSA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data about courses is stored in a CSV file. Here are the steps to load data from any csv file into Amazon DynamoDB.\n",
    "\n",
    "\n",
    "- Create the pandas dataframe from the source data\n",
    "\n",
    "- Convert dataframe to list of dictionaries (JSON) that can be consumed by any no-sql database\n",
    "\n",
    "- Put the JSON object created from the dataframe using put_item method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the pandas dataframe from the source data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "create_dynamodb_table(\"dsa_courses\",\"courseid\",\"N\")\n",
    "table = dynamodb.Table('dsa_courses')\n",
    "\n",
    "df=pd.read_csv('dsa_courses.csv')\n",
    "\n",
    "df.columns=[\"courseid\",\"coursename\",\"credits\"]\n",
    "\n",
    "\n",
    "print(\"\\n Top 5 rows of data in input file\",df.head())\n",
    "\n",
    "\n",
    "# Convert dataframe to list of dictionaries (JSON) that can be consumed by any no-sql database\n",
    "json_data=df.T.to_dict().values()\n",
    "\n",
    "for course in json_data:\n",
    "    table.put_item(Item=course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "response = table.get_item(Key={'courseid': 8610})\n",
    "response[\"Item\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scan\n",
    "\n",
    "The scan method reads every item in the entire table unlike get.item() and returns all the data in the table. An optional filter_expression if provided, filters the items matching the criteria and are returned. However, the filter is applied only after the entire table has been scanned. \n",
    "\n",
    "**FilterExpression** used below specifies a condition that returns only items that satisfy the condition. All other items are discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scan_table(table_name, filter_key=None, filter_value=None):\n",
    "    \"\"\"\n",
    "    Perform a scan operation on table.\n",
    "    Can specify filter_key (col name) and its value to be filtered.\n",
    "    \"\"\"\n",
    "    table = dynamodb.Table(table_name)\n",
    "\n",
    "    # Sample filter expression -  Key('year').between(1950, 1959);\n",
    "    # If there is a filtering expression given as input then records are filtered. Else, just return all records.\n",
    "\n",
    "    if filter_key and filter_value:\n",
    "        filtering_exp = Key(filter_key).eq(filter_value)\n",
    "        response = table.scan(FilterExpression=filtering_exp)\n",
    "    else:\n",
    "        response = table.scan()\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display table contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Display all the items in dsa_courses table\n",
    "scan_table(\"dsa_courses\")[\"Items\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stream tweets\n",
    "\n",
    "### Tweepy library for streaming twitter data\n",
    "\n",
    "[Read this doc](http://docs.tweepy.org/en/v3.4.0/streaming_how_to.html) for more information on the functions provided by Tweepy package\n",
    "\n",
    "The Twitter streaming API is used to download twitter messages in real time. It is useful for obtaining a high volume of tweets, or for creating a live feed using a site stream or user stream\n",
    "\n",
    "In Tweepy, an instance of tweepy.Stream establishes a streaming session and routes messages to StreamListener instance. The on_data method of a stream listener receives all messages and calls functions according to the message type.\n",
    "\n",
    "Therefore using the streaming api has three steps.\n",
    "\n",
    "* Create a class inheriting from StreamListener\n",
    "* Using that class create a Stream object\n",
    "* Connect to the Twitter API using the Stream.\n",
    "\n",
    "##### Step 1: Creating a StreamListener\n",
    "\n",
    "Create class MyStreamListener inheriting from StreamListener. There are different methods available. For example, override on_status() mathod to print status text. The on_data method of Tweepy’s StreamListener conveniently passes data from statuses to the on_status method.\n",
    "\n",
    "``` bash\n",
    "\n",
    "import tweepy\n",
    "#override tweepy.StreamListener to add logic to on_status\n",
    "class MyStreamListener(tweepy.StreamListener):\n",
    "\n",
    "    def on_status(self, status):\n",
    "        print(status.text)\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "##### Step 2: Creating a Stream\n",
    "\n",
    "We need an api to stream. See Authentication Tutorial to learn how to get an api object. Once we have an api and a status listener we can create our stream object.:\n",
    "\n",
    "``` bash\n",
    "myStreamListener = MyStreamListener()\n",
    "myStream = tweepy.Stream(auth = api.auth, listener=myStreamListener())\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "##### Step 3: Starting a Stream\n",
    "A tweet stream uses a filter in both user_stream or the sitestream. In below example, it is filtering to stream all tweets containing the words India and America. The track parameter is an array of search terms to stream.\n",
    "\n",
    "``` bash\n",
    "myStream.filter(track=['India','America'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(\"Output.txt\", \"w\")\n",
    "file.write (\"tweetid,text\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below code cell, we are using Tweepy library to create a twitter stream, collects tweets for 10 seconds from the stream and write them to a text file called \"Output.txt\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import the necessary methods from tweepy library\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "import tweepy\n",
    "import json\n",
    "import time\n",
    "\n",
    "# import logging\n",
    "# import time\n",
    "# from logging.handlers import RotatingFileHandler\n",
    "\n",
    "# Twitter security credentials \n",
    "ACCESS_TOKEN    = \"908803963557941248-sRHYClIfMteyPMnwF4hWkARyuHNkJRT\"\n",
    "ACCESS_SECRET   = \"FgGi0GshGh8Xbi0Tmkbks0G4Jvd20J5tTThCLJzxd0UVB\"\n",
    "CONSUMER_KEY    = \"KZT7UkCSyLhVO18Wqx6OJISDY\"\n",
    "CONSUMER_SECRET = \"X6hfBxJZz3jLqo8VeX451d7zW8u8v6yDqpiWTUWoq7hnGQTrp2\"\n",
    "\n",
    "start_time = time.time() #grabs the system time\n",
    "\n",
    "\n",
    "# \"listener\" class is inheriting from StreamListener. Implement StreamListener to get the stream.\n",
    "class listener(StreamListener):\n",
    "    #This is a basic listener that just writes received tweets to file.   \n",
    "    \n",
    "    # Initialize the instance\n",
    "    def __init__(self, time_limit=5):\n",
    "        self.time = time.time()\n",
    "        self.limit = time_limit\n",
    "#         super(listener, self).__init__()\n",
    "            \n",
    "    #on_data is one of the methods in StreamListener class. It will automatically figure out what kind of data Twitter sent, \n",
    "    #and call an appropriate method to deal with the specific data type. It’s possible to deal with events like users \n",
    "    # sending direct messages, tweets being deleted, and more.\n",
    "    def on_data(self, data):\n",
    "        if (time.time() - self.time) < self.limit:\n",
    "            with open(\"Output.txt\", \"a\") as tweet_log:\n",
    "                try:\n",
    "                    # Twitter returns data in JSON format - we need to decode it first\n",
    "                    decoded = json.loads(data)\n",
    "                    msg = '%s\\t%s\\n' % (decoded['user']['screen_name'], decoded['text'].encode('ascii', 'ignore'))\n",
    "                    tweet_log.write(msg)\n",
    "                    return True\n",
    "\n",
    "                except BaseException as e:\n",
    "                    print('failed ondata,', str(e))\n",
    "                    time.sleep(5)\n",
    "                    pass\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    # Ignore retweets. The tweet that is passed into the on_status method is an instance of the Status class. \n",
    "    # This class has properties describing the tweet, including the property retweeted_status, which tells us whether or \n",
    "    # not the tweet is a retweet.\n",
    "    # Modify the on_status function to filter out retweets. If the retweeted_status property exists, don’t process the tweet.\n",
    "    def on_status(self, status):\n",
    "        if status.retweeted_status:\n",
    "            return\n",
    "    \n",
    "\n",
    "#This handles Twitter authetification and the connection to Twitter Streaming API\n",
    "#Setup tweepy to authenticate with Twitter\n",
    "auth = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "\n",
    "#Create an API object to pull data from Twitter – we’ll pass in the authentication:\n",
    "\n",
    "# api = tweepy.API(auth)\n",
    "\n",
    "#Create an instance of the tweepy Stream class, which will stream the tweets. \n",
    "# stream_listener = StreamListener()\n",
    "\n",
    "#Pass auth credentials so that Twitter allows to connect. \n",
    "#Start streaming tweets by calling the filter method. This will start streaming tweets from the filter.json API endpoint.\n",
    "#We pass in a list of terms to filter on, as the API requires.\n",
    "twitterStream = Stream(auth, listener(time_limit=10)) #initialize Stream object with a time out limit\n",
    "twitterStream.filter(track=['India','America'], languages=['en'])  \n",
    "\n",
    "#This line filter Twitter Streams to capture data by whatever keywords you want to filter with, for example: 'India','America'\n",
    "# stream.filter(track=['India','America'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:\n",
    "\n",
    "Check if TwitterAnalysis table already exists in the DynamoDB. Run list_tables() method to list all the tables present in the database. The last line in the output tells what all tables exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table_name='TwitterAnalysis'\n",
    "\n",
    "response = client.list_tables()\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you see the table called TwitterAnalysis in the output of above cell, uncomment below code lines and run the cell. \n",
    "# It will delete the existing table. \n",
    "\n",
    "# response = client.delete_table(\n",
    "#     TableName='TwitterAnalysis'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create TwitterAnalysis table and populate it with the tweets in Output.txt \n",
    "\n",
    "Follow the steps discussed above to write csb file to DynamoDB table\n",
    "\n",
    "- Create the pandas dataframe from the source data\n",
    "\n",
    "- Convert dataframe to list of dictionaries (JSON) that can be consumed by any no-sql database\n",
    "\n",
    "- Put the JSON object created from the dataframe using put_item method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_dynamodb_table(table_name,\"tweetid\",\"S\")\n",
    "table = dynamodb.Table(table_name)\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.read_csv('Output.txt',sep='\\t')\n",
    "\n",
    "df.columns=[\"tweetid\",\"text\"]\n",
    "\n",
    "print(\"\\n Top 5 rows of data in input file\\n\\n\",df.head())\n",
    "\n",
    "\n",
    "# Convert dataframe to list of dictionaries (JSON) that can be consumed by any no-sql database\n",
    "json_data=df.T.to_dict().values()\n",
    "\n",
    "for tweet in json_data:\n",
    "    table.put_item(Item=tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = client.describe_table(\n",
    "    TableName=table_name\n",
    ")\n",
    "response\n",
    "# scan_table(\"TwitterAnalysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = client.scan(\n",
    "    TableName=table_name\n",
    "    Select='ALL_ATTRIBUTES'\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete the table\n",
    "\n",
    "Delete the table by running below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = client.delete_table(\n",
    "    TableName=table_name\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
