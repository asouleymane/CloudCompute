{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3  -  Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exercises in this are partially complete. The data used in this notebook is taken from [kaggle website](). The data is about Climate Change, Earth Surface Temperature. We will load the data into reshift cluster and query the data. We will generate visualizations based on the data extracted from the redshift database table. \n",
    "\n",
    "\n",
    "**Note: ** The questions are highlighted in red. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import psycopg2\n",
    "from getpass import getpass\n",
    "from pandas import read_sql\n",
    "import datetime\n",
    "\n",
    "redshift_client = boto3.client('redshift')\n",
    "\n",
    "# Give a password to your redshift cluster\n",
    "pwd = getpass('password')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the names of the security group for the cluster, names of the cluster and database itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Sec_group_name= \"climate_sec_group\"\n",
    "cluster_name=\"climate\"\n",
    "database_name=\"climatecitydata\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an AWS EC2 client object to create a security group for the redshift cluster. We are going to deploy the cluster with default parameters already set using aws configure command. \n",
    "\n",
    "If you still haven't gone through AWS command line interface tools, we strongly recommend you to do it by clikcing the link below.\n",
    "\n",
    "[click here to open the lab Accesing_AWS_through_CLI](../../module2/extra_labs/Accessing_AWS_through_CLI.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ec2_client = boto3.client('ec2')\n",
    "\n",
    "# The function will take the default credentials stored in configure file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<span style=\"color:red\"><b>Activity 1:</b> Create a security group named \"redshift_Sec_group\".</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sg = ec2_client.create_security_group(\n",
    "    \n",
    "    ## you code for activity 1 goes here\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit the security group inbound rules to allow all TCP/IP traffic on port number 5439. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sec_rule=\"ALL TCP\"\n",
    "    data = ec2_client.authorize_security_group_ingress(\n",
    "        GroupId=Sec_group,\n",
    "        IpPermissions=[\n",
    "            {'IpProtocol': 'tcp',\n",
    "             'FromPort': 5439,\n",
    "             \n",
    "             'ToPort': 5439,\n",
    "             'IpRanges': [{'CidrIp': '0.0.0.0/0'}]},\n",
    "        ],)\n",
    "    print(\"Ingress \"+sec_rule+\" added\")\n",
    "except:\n",
    "    print(sec_rule+\" already added\")\n",
    "#     print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a keypair\n",
    "\n",
    "Create a keypair for the EC2 instance. We first generate a name to create a key with that name and also store the key in a file. ec2.create_key_pair() will create a keypair. System command echo is used to write the contents of keypair generated to a file created with same name as keypair. \n",
    "\n",
    "You have to modify the file permissions to provide readonly access. If the file is open, system will throw an error. Do chmod(file, 0o400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import os\n",
    "import getpass\n",
    "from subprocess import call\n",
    "\n",
    "#Set the username from system\n",
    "system_user_name=getpass.getuser()\n",
    "\n",
    "ec2_pem_file=time.strftime(\"EC2-%d%m%Y%H%M%S-\"+system_user_name)\n",
    "ec2_key=ec2_client.create_key_pair(KeyName=ec2_pem_file)\n",
    "\n",
    "#Don't do this unless you have a good reason\n",
    "#print(emr_key['KeyMaterial'])\n",
    "\n",
    "os.system(\"echo \\\"\"+ec2_key['KeyMaterial']+\"\\\" > \"+ec2_pem_file+\".pem\")\n",
    "os.chmod(ec2_pem_file+\".pem\",0o400)\n",
    "\n",
    "print(\"KeyName         : \"+ec2_key['KeyName']+\"\\nKey Fingerprint : \"+ec2_key['KeyFingerprint'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<span style=\"color:red\"><b>Activity 2:</b> Deploy a redshift cluster with default database as \"climatecitydata\" stored in the variable \"database_name\". The cluster should have 2 slave nodes. Use the security group created above for creating the cluster.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = redshift_client.create_cluster(\n",
    "    \n",
    "    ## you code for activity 2 goes here\n",
    "\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Once the cluster is created use the below poll function to check the status of the cluster. Once it is in ready state the poll function will indicate the cluster is ready for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def poll_until_completed(client, cluster_id):\n",
    "    delay = 2\n",
    "    while True:\n",
    "        cluster = client.describe_clusters(ClusterIdentifier=cluster_id)\n",
    "#         for tag in cluster:\n",
    "#             print(tag)\n",
    "#         print(cluster)\n",
    "#         print(cluster['Clusters'][0]['ClusterIdentifier'])\n",
    "        status = cluster['Clusters'][0]['ClusterStatus']\n",
    "#         message = cluster.get('Message', '')\n",
    "        now = str(datetime.datetime.now().time())\n",
    "        print(\"cluster %s is %s at %s\" % (cluster_id, status, now))\n",
    "        if status in ['available', 'final-snapshot']:\n",
    "            break\n",
    "\n",
    "        # exponential backoff with jitter\n",
    "        delay *= random.uniform(1.1, 2.0)\n",
    "        time.sleep(delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poll_until_completed(redshift_client, cluster_id=cluster_name)  # Can't use the cluster until it is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run the cell if you want to see the complete details of cluster. \n",
    "\n",
    "# redshift_client.describe_clusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect to the cluster we need its endpoint. Below cell prints the end point, the default port where the cluster is listening for input requests and the database available in the cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_end_point = ''\n",
    "for cluster in redshift_client.describe_clusters()[\"Clusters\"]:\n",
    "    print(\"Cluster endpoint:\",str(cluster[\"Endpoint\"][\"Address\"])+\"\\n\"+\"Port:\",str(cluster[\"Endpoint\"][\"Port\"])+\"\\n\"+\"Database:\",str(cluster[\"DBName\"]))\n",
    "    cluster_end_point = str(cluster[\"Endpoint\"][\"Address\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code cell prints the public and private addresses of the nodes in cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in redshift_client.describe_clusters()[\"Clusters\"]:\n",
    "    for ClusterNode in cluster[\"ClusterNodes\"]:\n",
    "        if cluster_name in cluster[\"Endpoint\"][\"Address\"]:\n",
    "            print(ClusterNode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<span style=\"color:red\"><b>Activity 3:</b> Create a connection string to connect to redshift cluster created above</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn_string = { \n",
    "    \n",
    "        ## you code for activity 3 goes here\n",
    "\n",
    "    \n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the connection string is available, use the create_conn() method to create a connection object to connect to \"climatecitydata\" database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_conn(config):\n",
    "    try:\n",
    "        con=psycopg2.connect(dbname=config['dbname'], host=config['host'], \n",
    "                              port=config['port'], user=config['user'], \n",
    "                              password=config['pwd'])\n",
    "        return con\n",
    "    except Exception as err:\n",
    "        print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con = create_conn(config=conn_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have established the connection to redshift cluster using psycopg library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data into Redshift cluster\n",
    "\n",
    "The data is already uploaded to S3 bucket 'skaf48bucket00' and should be publicly accesible. So create a redshift table and copy the data from S3 into the table. \n",
    "\n",
    "Create a table called \"dsaclimatecitydata\" using below statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "statement=\"\"\"create table dsaclimatecitydata (dt date,averagetemperature numeric(10,5),\n",
    "            averagetemperatureuncertainty numeric(10,5),city varchar(25),country varchar(34),\n",
    "            latitude varchar(6),longitude varchar(7));\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a cursor object and execute above statement to create the table.\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute(statement)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# con.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<span style=\"color:red\">Note: </span>\n",
    "\n",
    "    Update the blanks for access id and secret key in below cell. Run the updated cell to copy data from S3 file to the database table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"copy dsaclimatecitydata from 's3://\"\"\"+bucket_name+\"\"\"/GlobalLandTemperaturesByCity.csv'\n",
    "    access_key_id '<give your credentials>'\n",
    "    secret_access_key '<give your credentials>'\n",
    "    region 'us-east-1'\n",
    "    ignoreheader 1\n",
    "    null as 'NA'\n",
    "    removequotes\n",
    "    delimiter ',';\"\"\"\n",
    "cur.execute(sql)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Uncomment below lines and run the table if the database throws any error. The stl_load_errors table captures the error \n",
    "# messages. \n",
    "\n",
    "# df=read_sql(\"select *from stl_load_errors\",con)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_sql(\"select * from dsaclimatecitydata limit 10;\",con=con)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a table and load the data into Redshift. We established connection to the cluster above. Use the connection object \"con\" to execute create table srtatement.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_sql(\"select column_name, data_type, character_maximum_length \\\n",
    "from INFORMATION_SCHEMA.COLUMNS where table_name = 'dsaclimatecitydata';\",con=con)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will stage the data on S3 first before writing it to redshift cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_sql(\"\"\"select * from dsaclimatecitydata where city = 'Hyderabad' limit 5;\"\"\",con)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<span style=\"color:red\"><b>Activity 4:</b> Create a new table called dsaclimatesubsetdata1 with columns dt, averagetemperature, month, year, city, country, latitude, longitude and the column dt as primary key. Use select query on dsaclimatecitydata table to create the table. \n",
    "\n",
    "Hint: The columns month, year are created by extracting month and year from dt column. \n",
    "\n",
    "</span>\n",
    "\n",
    "Sample table output: \n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\tdt\taveragetemperature\tmonth\tyear\tcity\tcountry\tlatitude\tlongitude\n",
    "0\t1743-11-01\t5.339\t11.0\t1743.0\tAlexandria\tUnited States\t39.38N\t76.99W\n",
    "1\t1743-11-01\t7.431\t11.0\t1743.0\tAlmere\tNetherlands\t52.24N\t5.26E\n",
    "2\t1743-11-01\t-5.556\t11.0\t1743.0\tAlmetyevsk\tRussia\t55.45N\t51.02E\n",
    "3\t1743-11-01\t7.431\t11.0\t1743.0\tAmersfoort\tNetherlands\t52.24N\t5.26E\n",
    "4\t1743-11-01\t3.510\t11.0\t1743.0\tArmavir\tRussia\t45.81N\t40.38E\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "statement = \"\"\"create table dsaclimatesubsetdata1 ....... \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute(statement)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_sql(\"\"\"select * from dsaclimatesubsetdata1 limit 5;\"\"\",con)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_sql(\"select column_name, data_type, character_maximum_length \\\n",
    "from INFORMATION_SCHEMA.COLUMNS where table_name = 'dsaclimatesubsetdata1';\",con=con)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<span style=\"color:red\"><b>Activity 5:</b> Select median of averagetemperature as column named median and year from the table dsaclimatesubsetdata. Group the data by year. Order the data in ascending of year.  \n",
    "\n",
    "</span>\n",
    "\n",
    "\n",
    "Sample output\n",
    "\n",
    "```\n",
    "\n",
    "\tmedian\tyear\n",
    "0\t5.354\t1743.0\n",
    "1\t11.552\t1744.0\n",
    "2\t2.196\t1745.0\n",
    "3\t0.000\t1746.0\n",
    "4\t0.000\t1747.0\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill the empty quotes to answer activity 5\n",
    "\n",
    "df = read_sql(\"\"\"  \"\"\",con)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<span style=\"color:red\"><b>Activity 6:</b>  Use the data in variable df in above cell to plot year on x-axis and median on y-axis. \n",
    "\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the data\n",
    "plt.plot( ## your code for activity 6 goes here )\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<span style=\"color:red\"><b>Activity 7:</b> Select median of averagetemperature as column named median and year from the table dsaclimatesubsetdata. Group the data by year. Order the data in ascending of year and year is >=1900.  \n",
    "\n",
    "PLot the year on x-axis and median on y-axis once the query results are obtained\n",
    "\n",
    "</span>\n",
    "\n",
    "\n",
    "Sample output\n",
    "\n",
    "```\n",
    "\n",
    "median\tyear\n",
    "0\t20.0940\t1900.0\n",
    "1\t19.9100\t1901.0\n",
    "2\t19.8990\t1902.0\n",
    "3\t19.5085\t1903.0\n",
    "4\t19.5590\t1904.0\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill the empty quotes to answer activity 7\n",
    "\n",
    "df = read_sql(\"\"\"   \"\"\",con)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the data\n",
    "plt.plot( ## your code for activity 7 goes here )\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "\n",
    "trace=go.Scatter(\n",
    "    x=df['year'],\n",
    "    y=df['median'],\n",
    "    mode='lines',\n",
    "    )\n",
    "data=[trace]\n",
    "\n",
    "py.iplot(data, filename='line-mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<span style=\"color:red\"><b>Activity 8:</b> Select median of averagetemperature as column named median, year, country from the table dsaclimatesubsetdata where country is among ['United States','China','India','Japan','Germany','United Kingdom']. Group the data by year. Order the data in ascending of year and year is >=1950.  \n",
    "\n",
    "\n",
    "</span>\n",
    "\n",
    "\n",
    "Sample output\n",
    "\n",
    "```\n",
    "\n",
    "\tmedian\tyear\tcountry\n",
    "0\t26.163995\t1950.0\tIndia\n",
    "1\t15.168995\t1950.0\tChina\n",
    "2\t8.500000\t1950.0\tUnited Kingdom\n",
    "3\t7.484000\t1950.0\tGermany\n",
    "4\t13.644000\t1950.0\tJapan\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill the empty quotes to answer activity 8\n",
    "\n",
    "df = read_sql(\"\"\"   \"\"\",con)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc=df.pivot('year','country','median')\n",
    "f,ax=plt.subplots(figsize=(20,10))\n",
    "abc.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<span style=\"color:red\"><b>Activity 9:</b> Select max of averagetemperature as column named max_temp, country from the table dsaclimatesubsetdata. Group the data by country. Order the data by descending order of max_temp. Limit the results to count 20.\n",
    "\n",
    "\n",
    "Use a barplot as shown in labs and plot the temperatures on y-axis and countries on x-axis.\n",
    "\n",
    "</span>\n",
    "\n",
    "\n",
    "Sample output\n",
    "\n",
    "```\n",
    "\n",
    "\tmax_temp\tcountry\n",
    "0\t39.651\tAlgeria\n",
    "1\t39.156\tIran\n",
    "2\t38.283\tIraq\n",
    "3\t38.049\tSaudi Arabia\n",
    "4\t37.938\tPakistan\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill the empty quotes to answer activity 9\n",
    "\n",
    "df = read_sql(\"\"\"    \"\"\",con)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Complete the code to answer activity 9\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "bar_plot = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# response = redshift_client.delete_cluster(\n",
    "#     ClusterIdentifier='climate',\n",
    "#     SkipFinalClusterSnapshot=True\n",
    "# )\n",
    "\n",
    "response = redshift_client.delete_cluster(\n",
    "    ClusterIdentifier='climate',\n",
    "    SkipFinalClusterSnapshot=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
