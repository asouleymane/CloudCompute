{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Google Cloud Platform (GCP) Data Scraper\n",
    "\n",
    "For this exercise, which will be built upon next week, we are going to stand up GCP resources to scrape [REDDIT](https://www.reddit.com/).\n",
    "This scraping will be done by tapping into the REDDIT RSS Feeds.  \n",
    "\n",
    "[Read about RSS here](https://en.wikipedia.org/wiki/RSS).\n",
    "\n",
    "### Overview\n",
    "\n",
    " 1. Create an Storage Bucket to collect the data\n",
    " 1. Create a preemptible Compute Engine\n",
    " 1. Install software on compute engine\n",
    " 1. Write additional code modules to collect data into the bucket\n",
    " 1. Collect data and write to storage bucket\n",
    " \n",
    "#### Data Scraper Concept Overview\n",
    " \n",
    "![DataScraperStructure_Mini_Project1.png MISSING](../images/DataScraperStructure_Mini_Project1.png)\n",
    "\n",
    "\n",
    "**Note:** Please use the <span style=\"background:yellow\">**us-central1**</span> region for all activities!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create a Storage Bucket\n",
    "\n",
    "Link: https://console.cloud.google.com/storage/\n",
    " * Name: **dsa_mini_project**\n",
    " * Select a Regional storage class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create a Preemptible Compute Engine (VM)\n",
    "\n",
    "Link: https://console.cloud.google.com/compute/instances\n",
    " * Name: **dsa-mini-project**\n",
    " * Select Micro Instance\n",
    "![DataScraperVM_Instance.png MISSING](../images/DataScraperVM_Instance.png)\n",
    "\n",
    "\n",
    "**BE SURE TO MAKE IT PREEMPTIBLE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Install software on compute engine\n",
    "\n",
    "**You will need to install software to your compute engine (VM)**\n",
    " * [RSS Feed Libraries](https://wiki.python.org/moin/RssLibraries)\n",
    " * [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/)\n",
    " \n",
    "\n",
    "Also read through this helpful information about accessing Reddit RSS Feeds: \n",
    "https://www.reddit.com/r/pathogendavid/comments/tv8m9/pathogendavids_guide_to_rss_and_reddit/\n",
    "\n",
    "##### Here is some sample python code to pull the REDDIT feed and just print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import feedparser\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "\n",
    "# Functions from: https://stackoverflow.com/questions/1936466/beautifulsoup-grab-visible-webpage-text\n",
    "\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    return u\" \".join(t.strip() for t in visible_texts)\n",
    "\n",
    "# Define URL of the RSS Feed I want\n",
    "a_reddit_rss_url = 'http://www.reddit.com/new/.rss?sort=new'\n",
    "\n",
    "feed = feedparser.parse( a_reddit_rss_url )\n",
    "\n",
    "if (feed['bozo'] == 1):\n",
    "    print(\"Error Reading/Parsing Feed XML Data\")    \n",
    "else:\n",
    "    for item in feed[ \"items\" ]:\n",
    "        dttm = item[ \"date\" ]\n",
    "        title = item[ \"title\" ]\n",
    "        summary_text = text_from_html(item[ \"summary\" ])\n",
    "        link = item[ \"link\" ]\n",
    "        \n",
    "        print(\"====================\")\n",
    "        print(\"Title: {} ({})\\nTimestamp: {}\".format(title,link,dttm))\n",
    "        print(\"--------------------\\nSummary:\\n{}\".format(summary_text))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Write additional code modules to collect data into the bucket\n",
    "\n",
    "Since you have created a preemptible VM, it may disappear at any time.\n",
    "\n",
    "### ADD MORE \"Raw NBConvert\" Cells as needed for code you want to save\n",
    "\n",
    "### This is also part of your submitted work for this module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"background:yellow\">To-Do</span>\n",
    "\n",
    "You will need to build off of RSS Feed Scrape code to write a JSON formatted file of data from when I showed above (title,url,summary, date/time) for each time the code runs.\n",
    "The files should get a unique name each time, possibly look to making a file name from the run time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpful Link for Writing to the Cloud Storage\n",
    "\n",
    "https://cloud.google.com/appengine/docs/standard/python/googlecloudstorageclient/read-write-to-cloud-storage"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Write your Code Segments here, \n",
    "##  because your VM will get deleted\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Write your additional Code Segments here, \n",
    "##  because your VM will get deleted\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Collect data and write to storage bucket\n",
    "\n",
    "### 5.1 Package your scrapping code into a script: `data_scrape1.py`.\n",
    "You can either write this locally and upload or create the script directly on VM.\n",
    "\n",
    "\n",
    "### 5.2 Run the script a few times / minutes\n",
    "\n",
    "### 5.3 Get a listing of the contents of your bucket and paste into the cell below.\n",
    "\n",
    "#### Optionally\n",
    "You can grab a screen shot of the bucket contents from the console and imbed it below using the \n",
    "```\n",
    "![my screenshot](screen_shot.png)\n",
    "```\n",
    "and changing the cell to _Markdown_.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Paste Bucket listing here ... or \n",
    "# Use the this ![my screenshot](screen_shot.png) to embed an uploaded image named \"screen_shot.png\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You can now go the VM console and Stop your instance. \n",
    "\n",
    "Then you can restart it next week to continue building it up instead of starting it over.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Where is this exercise going?\n",
    "\n",
    "Next module you will be introduced to various GCP Cloud APIs for things like Vision, Natural Language, etc.\n",
    "\n",
    "You will be extending this scraper to utilize an API or two to process the data in the buckets.\n",
    "The processing will produce analytical information that will feed into BigQuery tables, thereby faciltitating analytics and visualizations!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your Notebook!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
