{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Cloud Computing \n",
    "-----\n",
    "\n",
    "Almost every person who uses a computer might have used cloud services at some point. \n",
    "Sooner or later everybody will use it as often as they are using their regular computers and mobile phones. \n",
    "We use cloud services with or without realising it everyday. \n",
    "For example, we are searching for things online which runs algorithms behind the scenes. \n",
    "We use storage for example in the form of emails, google drive for storing docs, or your favourite spotify music playlist. \n",
    "\n",
    "All these important services, which are used regularly are being moved to cloud. \n",
    "What is driving this move towards the cloud? \n",
    "Many industries are focusing on a transition to the cloud as their back end infrastructure. \n",
    "The economic model of cloud has revoltionized the way companies think of cyberinfrastructure. \n",
    "_Cloudonomics_, as they call it, will explain the economics of usage of cloud services. \n",
    "Cloud services are so tempting as it follows pay per use model and you only use computing occasionally. \n",
    "Typically, you may use large amounts of resources for a brief amount of time. \n",
    "For example, companies that offer payroll services crunch enormours amount of data generating reports and statements once in a month. \n",
    "This kind of spike in the resources needed are handled very well in the cloud scenario which allows you to \n",
    "share the cloud infrastructure between tens of thousands, maybe millions of people. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "One of the biggest advantages of cloud computing is everyone will be paying just a small amount for a \n",
    "cloud service which is being shared among different people. \n",
    "Cloudonomics, which will be covered later in this module, is really all about how you benefit from having that shared environment. \n",
    "You might think your computer or your mobile phone is doing the work, \n",
    "but in fact cloud is working for you by taking the load off your work station. \n",
    "Everybody is sharing and all of a sudden the costs are divided. \n",
    "Anybody can get access a computer facility, which is enabled by this different type of economy. \n",
    "In next modules we will talk about big data, \n",
    "you will see how we are going to address large amounts of data and perform analytics \n",
    "by providing it in a very suitable form to use and to manage. \n",
    "The key thing would be how as a data scientist you would use cloud computing to perform data analytics. \n",
    "We will discuss some of the concepts and technologies that enable cloud computing.\n",
    "Additionally, we will emphasize the use of cloud computing for data analytics. \n",
    "\n",
    "---\n",
    "\n",
    "Imagine your laptop as a piece of hardware that you have to carry around.\n",
    "You put it in your bag and move around with it. \n",
    "In a similar way cloud is designed to have very, very large systems that are very modular in design, \n",
    "easy to change, very easy to access, and easy to construct businesses on top of information services. \n",
    "A _Software desined Architecture_ is what makes this possible. \n",
    "\n",
    "As data scientists, you will want to know what is underlying software defined architecture. \n",
    " * What are the interfaces to the software and services? \n",
    " * How do you use restful services to build applications that communicate easily on internet? \n",
    " * What does it mean to have virtualization? \n",
    "\n",
    "These are questions we will answer as we learn about cloud concepts and software defined architectures. \n",
    "Once you think of computing as a service, similar to electricity or water delivered to your residence, \n",
    "you can understand computing resources (CPUs, disk stores, networks, security,  and a huge number of basic elements) \n",
    "as a ubiquitous utility. \n",
    "Your model is now to pay as you use the resource; and as a business develop strategies to minimize waste of the resource (consumption conscious)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use cases\n",
    "\n",
    "Please take some time to read the following case studies!\n",
    "\n",
    "\n",
    "[Black board](https://aws.amazon.com/solutions/case-studies/blackboard/)\n",
    "\n",
    "[Netflix](https://aws.amazon.com/solutions/case-studies/netflix/)\n",
    "\n",
    "[Atlassian](https://aws.amazon.com/solutions/case-studies/atlassian/)\n",
    "\n",
    "[Discovery communications](https://aws.amazon.com/solutions/case-studies/discovery-communications/)\n",
    "\n",
    "[Evernote](http://www.pcworld.com/article/3167594/data-center-cloud/heres-how-evernote-moved-3-petabytes-of-data-to-googles-cloud.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more about Software Defined Architecture in below article. \n",
    "\n",
    "**Reference: ** [Software Defined Architecture](https://www.ciosummits.com/Online_Asset_Modulus_Whitepaper_-_Software-Defined_Architecture.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Age of Internet Computing\n",
    "\n",
    "Billions of people use the Internet every day. \n",
    "As a result, supercomputer sites and large data centers must provide high-performance computing services to huge numbers of Internet users concurrently. \n",
    "The emergence of computing clouds demands high-throughput computing (HTC) systems built with parallel and distributed computing technologies. \n",
    "We continually have to upgrade data centers using fast servers, storage systems, and high-bandwidth networks. \n",
    "The purpose is to advance network-based computing and web services with the emerging new technologies.\n",
    "\n",
    "From 1980 to 2000, massive numbers of portable computers and pervasive devices appeared in both wired and wireless applications. \n",
    "Since 1990, the use of both _high performance computing_ (HPC) and _high throughput computing_ (HTC) systems hidden in clusters, grids, and Internet clouds has proliferated. \n",
    "The general computing trend is to leverage shared web resources and massive amounts of data over the Internet.\n",
    "\n",
    "The below figure illustrates the evolution of HPC and HTC systems. \n",
    "On the HPC side, supercomputers (massively parallel processors or MPPs) are gradually replaced by \n",
    "clusters of cooperative computers out of a desire to share computing resources. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"../images/evolution_of_computing.PNG\">\n",
    "$$Figure\\ 1$$\n",
    "$$ Evolutionary\\ trend\\ toward\\ parallel,\\ distributed,\\ and\\ cloud\\ computing\\ with\\ clusters,\\ MPPs,\\ P2P\\ networks,\\ grids,\\ clouds,\\ web services,\\ and\\ the\\ Internet\\ of\\ Things $$\n",
    "\n",
    "\n",
    "<br>\n",
    "On the HTC side, peer-to-peer (P2P) networks are formed for distributed file sharing and content delivery applications. A P2P system is built over many client machines. Peer machines are globally distributed in nature. P2P, cloud computing, and web service platforms are more focused on HTC applications than on HPC applications. \n",
    "\n",
    "\n",
    "_From 1.1.1 in Distributed and Cloud Computing_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Paradigm Distinctions\n",
    "----\n",
    "In general, distributed computing is the opposite of centralized computing. \n",
    "The field of parallel computing overlaps with distributed computing to a great extent, \n",
    "and cloud computing overlaps with distributed, centralized, and parallel computing. \n",
    "The following list defines these terms more clearly.\n",
    "\n",
    " * **Centralized computing:** This is a computing paradigm by which all computer resources are centralized in one physical system. All resources (processors, memory, and storage) are fully shared and tightly coupled within one integrated OS. Many data centers and supercomputers are centralized systems, but they are used in parallel, distributed, and cloud computing applications.\n",
    "\n",
    "\n",
    " * **Parallel computing:** In parallel computing, all processors are either tightly coupled with centralized shared memory or loosely coupled with distributed memory. Some authors refer to this discipline as parallel processing. Interprocessor communication is accomplished through shared memory or via message passing. A computer system capable of parallel computing is commonly known as a parallel computer. Programs running in a parallel computer are called parallel programs. The process of writing parallel programs is often referred to as parallel programming.\n",
    "\n",
    "\n",
    " * **Distributed computing:** A distributed system consists of multiple autonomous computers, each having its own private memory, communicating through a computer network. Information exchange in a distributed system is accomplished through message passing. A computer program that runs in a distributed system is known as a distributed program. \n",
    "\n",
    "\n",
    " * **Cloud computing:** An Internet cloud of resources can be either a centralized or a distributed computing system. The cloud applies parallel or distributed computing, or both. Clouds can be built with physical or virtualized resources over large data centers that are centralized or distributed. Some authors consider cloud computing to be a form of utility computing or service computing.\n",
    "\n",
    "\n",
    " * **Ubiquitous computing: ** It refers to computing with pervasive devices at any place and time using wired or wireless communication. The Internet of Things (IoT) is a networked connection of everyday objects including computers, sensors, humans, etc. The IoT is supported by Internet clouds to achieve ubiquitous computing with any object at any place and time. \n",
    "\n",
    "\n",
    "This course places more emphasis on distributed and cloud computing and their working systems using Amazon Web Services and Google Cloud Platform.\n",
    "\n",
    "-----\n",
    "\n",
    "## Note \n",
    "\n",
    "* To read more about evolution of computing, go through [chapter 1 of Distributed and cloud computing](https://books.google.com/books/about/Distributed_and_Cloud_Computing.html?id=IjgVAgAAQBAJ&printsec=frontcover&source=kp_read_button#v=onepage&q&f=false). \n",
    "\n",
    "* You can access the [ebook](http://proquest.safaribooksonline.com/book/operating-systems-and-server-administration/virtualization/9780123858801/firstchapter) from Mizzou library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technologies for Network-Based Systems\n",
    "----\n",
    "\n",
    "Advancements in hardware, software, and network technologies have led to development of distributed computing systems.\n",
    "\n",
    "\n",
    "* **Multicore CPUs and Multithreading Technologies: ** Today, advanced CPUs or microprocessor chips assume a multicore architecture with dual, quad, six, or more processing cores. These processors exploit parallelism at ILP and TLP levels. As the figure shows, Moore’s law has proven to be pretty accurate in this case. The clock rate for these processors increased from 10 MHz for the Intel 286 to 4 GHz for the Pentium 4 in 30 years. However, the clock rate reached its limit on CMOS-based chips due to power limitations. The ILP([Instruction-level parallelism](https://en.wikipedia.org/wiki/Instruction-level_parallelism)) is highly exploited in modern CPU processors. ILP mechanisms include multiple-issue superscalar architecture, dynamic branch prediction, and speculative execution, among others. In addition, [DLP](https://en.wikipedia.org/wiki/Data_parallelism) and [TLP](Thread-level parallelism) are highly explored in graphics processing units (GPUs) that adopt a many-core architecture with hundreds to thousands of simple cores. A GPU is a graphics coprocessor or accelerator mounted on a computer’s graphics card or video card. A GPU offloads the CPU from tedious graphics tasks in video editing applications. Unlike CPUs, GPUs have a throughput architecture that exploits massive parallelism by executing many concurrent threads slowly, instead of executing a single long thread in a conventional microprocessor very quickly. GPUs allow massive parallelism, compared to only a few threads that can be handled by a conventional CPU. The CPU is optimized for latency caches, while the GPU is optimized to deliver much higher throughput with explicit management of on-chip memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/cpu_speeds.PNG\">$$Figure\\ 2$$\n",
    "\n",
    "* **Memory, Storage, and Wide-Area Networking:** The upper curve in Figure 1.10 plots the growth of DRAM chip capacity from 16 KB in 1976 to 64 GB in 2011. This shows that memory chips have experienced a 4x increase in capacity every three years. Memory access time did not improve much in the past. Eventually, power consumption, cooling, and packaging will limit large system development. Power increases linearly with respect to clock frequency and quadratic ally with respect to voltage applied on chips. Clock rate cannot be increased indefinitely.\n",
    "\n",
    "\n",
    "* **Virtual Machines and Virtualization Middleware: ** A conventional computer has a single OS image. This offers a rigid architecture that tightly couples application software to a specific hardware platform. Some software running well on one machine may not be executable on another platform with a different instruction set under a fixed OS. Virtual machines (VMs) offer novel solutions to underutilized resources, application inflexibility, software manageability, and security concerns in existing physical machines. Today, to build large clusters, grids, and clouds, we need to access large amounts of computing, storage, and networking resources in a virtualized manner. We need to aggregate those resources, and hopefully, offer a single system image. In particular, a cloud of provisioned resources must rely on virtualization of processors, memory, and I/O facilities dynamically. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"../images/vm.PNG\">\n",
    "$$Figure\\ 3$$\n",
    "$$ Three\\ VM\\ architectures\\ in\\ (b),\\ (c),\\ and\\ (d),\\ compared\\ with\\ the\\ traditional\\ physical\\ machine\\ shown\\ in\\ (a)$$\n",
    "\n",
    "\n",
    "In above figure, the host machine is equipped with the physical hardware, as shown at the bottom of the figure. An example is an x-86 architecture desktop running its installed Windows OS, as shown in part (a) of the figure. The VM can be provisioned for any hardware system. The VM is built with virtual resources managed by a guest OS to run a specific application. Between the VMs and the host platform, one needs to deploy a middleware layer called a virtual machine monitor (VMM). Figure 3 shows a native VM installed with the use of a VMM called a hypervisor in privileged mode. For example, the hardware has x-86 architecture running the Windows system.\n",
    "\n",
    "The guest OS could be a Linux system and the hypervisor is the XEN system developed at Cambridge University. This hypervisor approach is also called bare-metal VM, because the hypervisor handles the bare hardware (CPU, memory, and I/O) directly. Another architecture is the host VM shown in Figure 3(c). Here the VMM runs in nonprivileged mode. The host OS need not be modified. The VM can also be implemented with a dual mode, as shown in Figure 3(d). Part of the VMM runs at the user level and another part runs at the supervisor level. In this case, the host OS may have to be modified to some extent. Multiple VMs can be ported to a given hardware system to support the virtualization process. The VM approach offers hardware independence of the OS and applications. The user application running on its dedicated OS could be bundled together as a virtual appliance that can be ported to any hardware platform. The VM could run on an OS different from that of the host computer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Levels of Virtualization Implementation\n",
    "\n",
    "<img src=\"../images/virtualization.PNG\"> $$ Figure\\ 4$$\n",
    "\n",
    "After virtualization, different user applications managed by their own operating systems (guest OS) can run on the same hardware, independent of the host OS. The VMs are shown in the upper boxes of Figure 4, where applications run with their own guest OS over the virtualized CPU, memory, and I/O resources.\n",
    "\n",
    "\n",
    "The main function of the software layer for virtualization is to virtualize the physical hardware of a host machine into virtual resources to be used by the VMs, exclusively. This can be implemented at various operational levels as shown in figure 5 below. The virtualization software creates the abstraction of VMs by interposing a virtualization layer at various levels of a computer system. Common virtualization layers include the instruction set architecture (ISA) level, hardware level, operating system level, library support level, and application level \n",
    "\n",
    "<img src=\"../images/virtualization_levels.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Instruction Set Architecture Level**: At the ISA level, virtualization is performed by emulating a given ISA by the ISA of the host machine. For example, MIPS binary code can run on an x86-based host machine with the help of ISA emulation. With this approach, it is possible to run a large amount of legacy binary code written for various processors on any given new hardware host machine. Instruction set emulation leads to virtual ISAs created on any hardware machine. The basic emulation method is through code interpretation. An interpreter program interprets the source instructions to target instructions one by one. One source instruction may require tens or hundreds of native target instructions to perform its function. \n",
    "\n",
    "* **Hardware Abstraction Level**: Hardware-level virtualization is performed right on top of the bare hardware. On the one hand, this approach generates a virtual hardware environment for a VM. On the other hand, the process manages the underlying hardware through virtualization. The idea is to virtualize a computer’s resources, such as its processors, memory, and I/O devices. The intention is to upgrade the hardware utilization rate by multiple users concurrently. \n",
    "\n",
    "* **Operating System Level**: This refers to an abstraction layer between traditional OS and user applications. OS-level virtualization creates isolated containers on a single physical server and the OS instances to utilize the hardware and software in data centers. The containers behave like real servers. OS-level virtualization is commonly used in creating virtual hosting environments to allocate hardware resources among a large number of mutually distrusting users. \n",
    "\n",
    "* **Library Support Level**: Most applications use APIs exported by user-level libraries rather than using lengthy system calls by the OS. Since most systems provide well-documented APIs, such an interface becomes another candidate for virtualization. Virtualization with library interfaces is possible by controlling the communication link between applications and the rest of a system through API hooks. The software tool WINE has implemented this approach to support Windows applications on top of UNIX hosts. Another example is the vCUDA which allows applications executing within VMs to leverage GPU hardware acceleration. \n",
    "\n",
    "* **User-Application Level**: Virtualization at the application level virtualizes an application as a VM. On a traditional OS, an application often runs as a process. Therefore, application-level virtualization is also known as process-level virtualization. The most popular approach is to deploy high level language (HLL) VMs. In this scenario, the virtualization layer sits as an application program on top of the operating system, and the layer exports an abstraction of a VM that can run programs written and compiled to a particular abstract machine definition. Any program written in the HLL and compiled for this VM will be able to run on it. The Microsoft .NET CLR and Java Virtual Machine (JVM) are two good examples of this class of VM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Note\n",
    "\n",
    "* To read more about Virtualization levels, go through [3.1 of Distributed and cloud computing](https://books.google.com/books/about/Distributed_and_Cloud_Computing.html?id=IjgVAgAAQBAJ&printsec=frontcover&source=kp_read_button#v=onepage&q&f=false). \n",
    "\n",
    "\n",
    "* You can access the [ebook](http://proquest.safaribooksonline.com/book/operating-systems-and-server-administration/virtualization/9780123858801/introduction/st0010_itr002_html#X2ludGVybmFsX0h0bWxWaWV3P3htbGlkPTk3ODAxMjM4NTg4MDElMkZzdDAwMTVfY2hwMDAzX2h0bWwmcXVlcnk9) from Mizzou library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Virtual Infrastructures: \n",
    "Physical resources for compute, storage, and networking are mapped to the needy applications embedded in various VMs at the top. \n",
    "Hardware and software are then separated. \n",
    "Virtual infrastructure is what connects resources to distributed applications. \n",
    "It is a dynamic mapping of system resources to specific applications. \n",
    "The result is decreased costs and increased efficiency and responsiveness.\n",
    "\n",
    "* **Data Center Virtualization for Cloud Computing: ** Cloud architecture is built with commodity hardware and network devices. Almost all cloud platforms choose the popular x86 processors. Low-cost terabyte disks and Gigabit Ethernet are used to build data centers. Data center design emphasizes the performance/price ratio over speed performance alone. In other words, storage and energy efficiency are more important than sheer speed performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Data Center Growth and Cost Breakdown\n",
    "A large data center may be built with thousands of servers. \n",
    "Smaller data centers are typically built with hundreds of servers. \n",
    "The cost to build and maintain data center servers has increased over the years. \n",
    "According to a 2009 IDC report (as shown in Figure 4), \n",
    "typically only 30 percent of data center costs goes toward purchasing IT equipment (such as servers and disks), \n",
    "33 percent is attributed to the chiller, 18 percent to the uninterruptible power supply (UPS), \n",
    "9 percent to computer room air conditioning (CRAC), \n",
    "and the remaining 7 percent to power distribution, lighting, and transformer costs. \n",
    "Thus, about 60 percent of the cost to run a data center is allocated to management and maintenance.\n",
    "\n",
    "<img src=\"../images/virtual_servers_spendings.PNG\">$$Figure\\ 4$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Low-Cost Design Philosophy\n",
    "High-end switches or routers may be too cost-prohibitive for building data centers. \n",
    "Thus, using high-bandwidth networks may not fit the economics of cloud computing. \n",
    "Given a fixed budget, commodity switches and networks are more desirable in data centers. \n",
    "Similarly, using commodity x86 servers is more desired over expensive mainframes. \n",
    "The software layer handles network traffic balancing, fault tolerance, and expandability. \n",
    "Currently, nearly all cloud computing data centers use Ethernet as their fundamental network technology.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###### Convergence of Technologies\n",
    "Essentially, cloud computing is enabled by the convergence of technologies in four areas: \n",
    "(1) hardware virtualization and multi-core chips, \n",
    "(2) utility and grid computing, \n",
    "(3) SOA, Web 2.0, and WS mashups, and \n",
    "(4) autonomic computing and data center automation. \n",
    "\n",
    "Hardware virtualization and multicore chips enable the existence of dynamic configurations in the cloud. \n",
    "Utility and grid computing technologies lay the necessary foundation for computing clouds. \n",
    "Recent advances in SOA, Web 2.0, and mashups of platforms are pushing the cloud another step forward. \n",
    "Finally, achievements in autonomic computing and automated data center operations contribute to the rise of cloud computing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Additional Readings\n",
    "\n",
    "[Read more about Virtual machines here](http://www.csd.uoc.gr/~hy428/reading/smith_nair_2005.pdf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
